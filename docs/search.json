[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Final Presentation\n\n\n\n\n\n\n\nResearch\n\n\nPresentation\n\n\n\n\n\n\n\n\n\n\n\nNov 29, 2023\n\n\nHemanth Allamaneni, Jaleon Braxton, Shivani Chowdary, Meghana Koduru\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 10\n\n\n\n\n\n\n\ncode\n\n\ngeolocation\n\n\ncensus\n\n\n\n\n\n\n\n\n\n\n\nNov 16, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 9\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 10, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 8\n\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nNov 8, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 7\n\n\n\n\n\n\n\ncode\n\n\ngraphs\n\n\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 6\n\n\n\n\n\n\n\ncode\n\n\ngraphs\n\n\n\n\n\n\n\n\n\n\n\nOct 14, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nResearch Proposal\n\n\n\n\n\n\n\nResearch\n\n\nPresentation\n\n\n\n\n\n\n\n\n\n\n\nOct 11, 2023\n\n\nHemanth Allamaneni, Jaleon Braxton, Shivani Chowdary, Meghana Koduru\n\n\n\n\n\n\n  \n\n\n\n\nAssignment 5\n\n\n\n\n\n\n\ncode\n\n\ngraphs\n\n\n\n\n\n\n\n\n\n\n\nOct 8, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nGgplot charts\n\n\n\n\n\n\n\ncode\n\n\ngraphs\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nAnsocombe examples\n\n\n\n\n\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nThe field of cognitive science, or not?\n\n\n\n\n\n\n\nanalysis\n\n\nart\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nSeason Colors\n\n\n\n\n\n\n\nart\n\n\ncode\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\n  \n\n\n\n\nGenerative art\n\n\n\n\n\n\n\nanalysis\n\n\nart\n\n\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nHemanth Allamaneni\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is blog used to publish my data analysis, exploration and various other observations!"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Anscombe examples/index.html",
    "href": "posts/Anscombe examples/index.html",
    "title": "Ansocombe examples",
    "section": "",
    "text": "These are all Anscombe examples, with pre-loaded dataset and code as provided.\n\n## Fancy version (per help file)\n\nff &lt;- y ~ x\nmods &lt;- setNames(as.list(1:4), paste0(\"lm\", 1:4))\n\n# Plot using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  ## or   ff[[2]] &lt;- as.name(paste0(\"y\", i))\n  ##      ff[[3]] &lt;- as.name(paste0(\"x\", i))\n  mods[[i]] &lt;- lmi &lt;- lm(ff, data = anscombe)\n  print(anova(lmi))\n}\n\nAnalysis of Variance Table\n\nResponse: y1\n          Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nx1         1 27.510 27.5100   17.99 0.00217 **\nResiduals  9 13.763  1.5292                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y2\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx2         1 27.500 27.5000  17.966 0.002179 **\nResiduals  9 13.776  1.5307                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y3\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx3         1 27.470 27.4700  17.972 0.002176 **\nResiduals  9 13.756  1.5285                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nAnalysis of Variance Table\n\nResponse: y4\n          Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nx4         1 27.490 27.4900  18.003 0.002165 **\nResiduals  9 13.742  1.5269                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsapply(mods, coef)  # Note the use of this function\n\n                  lm1      lm2       lm3       lm4\n(Intercept) 3.0000909 3.000909 3.0024545 3.0017273\nx1          0.5000909 0.500000 0.4997273 0.4999091\n\nlapply(mods, function(fm) coef(summary(fm)))\n\n$lm1\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0000909  1.1247468 2.667348 0.025734051\nx1          0.5000909  0.1179055 4.241455 0.002169629\n\n$lm2\n            Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.000909  1.1253024 2.666758 0.025758941\nx2          0.500000  0.1179637 4.238590 0.002178816\n\n$lm3\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0024545  1.1244812 2.670080 0.025619109\nx3          0.4997273  0.1178777 4.239372 0.002176305\n\n$lm4\n             Estimate Std. Error  t value    Pr(&gt;|t|)\n(Intercept) 3.0017273  1.1239211 2.670763 0.025590425\nx4          0.4999091  0.1178189 4.243028 0.002164602\n\n# Preparing for the plots\nop &lt;- par(mfrow = c(2, 2), mar = 0.1+c(4,4,1,1), oma =  c(0, 0, 2, 0))\n\n# Plot charts using for loop\nfor(i in 1:4) {\n  ff[2:3] &lt;- lapply(paste0(c(\"y\",\"x\"), i), as.name)\n  plot(ff, data = anscombe, col = \"red\", pch = 21, bg = \"orange\", cex = 1.2,\n       xlim = c(3, 19), ylim = c(3, 13))\n  abline(mods[[i]], col = \"blue\")\n}\nmtext(\"Anscombe's 4 Regression data sets\", outer = TRUE, cex = 1.5)\n\n\n\npar(op)"
  },
  {
    "objectID": "posts/generative art/index.html",
    "href": "posts/generative art/index.html",
    "title": "Generative art",
    "section": "",
    "text": "Generative Art is a process of algorithmically generating new ideas, forms, shapes, colors or patterns. First, you create rules that provide boundaries for the creation process. Then a computer follows those rules to produce new works on your behalf.\n\n\n\nSprawl, by Mark J. Stock. This generative artwork begins as a set of rules and a world (the initial condition). Sometimes it takes millions of iterations for a pattern to emerge, depending on the complexity of the algorithm and its conditions.\n\n\nIn his piece Sprawl above, Stock created a chaotic branching structure growing on a regular array of blocks. His dark growth is simulated using a surface-growth algorithm.\n\"The primary design element is from an algorithm called off-lattice diffusion-limited aggregation (DLA),\" Stock explains. \"Particles are seeded at specific locations and random walk until they strike any part of the existing structure, then they stick there. The whole thing is then radiosity rendered.\""
  },
  {
    "objectID": "posts/Colors/index.html",
    "href": "posts/Colors/index.html",
    "title": "Season Colors",
    "section": "",
    "text": "Winter colors\n\n\nThis is a generated image with winter colors."
  },
  {
    "objectID": "posts/Cognition_fields/index.html",
    "href": "posts/Cognition_fields/index.html",
    "title": "The field of cognitive science, or not?",
    "section": "",
    "text": "Fields of cognitive science\n\n\nThis image is often used to describe the ever growing domain of cognitive science, however due to a variety of reasons, it is my belief that this is an inadequately defined representation of the field.\nIt is also further inaccurate in the representation insofar as certain fields are more closely related than others and this visual representation does not take these weights into consideration either.\nFurther as an issue, the image does not represent a far enough branched out structure that would involve the sub domains and related fields such that the viewer may get a more comprehensive understanding of how the fields are correlated and what skills might be required to implement a solution or project in the domain.\nThe lay person may feel like they are obtaining a lot of information from this graphic but rather, they would be lacking key insights that would actually solidify the information that they are viewing. Although one could argue that the key purpose of the graphic is simply a simple visual introduction into the concept of what the domain of cognitive science holistically means as a whole, rather than specific parts of it, it is my opinion that the designer would have been better served using another differentiator such as color and an indication of what level of expertise the viewer must have reached before attempting to comprehend the subject matter at the color coded level."
  },
  {
    "objectID": "posts/Charts 1-4/index.html",
    "href": "posts/Charts 1-4/index.html",
    "title": "Research Proposal",
    "section": "",
    "text": "Presentation"
  },
  {
    "objectID": "posts/Proposal/index.html",
    "href": "posts/Proposal/index.html",
    "title": "Ggplot charts",
    "section": "",
    "text": "Chart 1\n\n# Load ggplot2\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Make data\ndata &lt;- data.frame(\n  group = c(\"A \", \"B \", \"C \", \"D \"),\n  value = c(50, 50, 56, 50),\n  number_of_obs = c(150, 250, 300, 275)\n)\n\n# Calculate the future positions on the x-axis of each bar (left border, central position, right border)\ndata$right &lt;- cumsum(data$number_of_obs) + 30 * (0:(nrow(data) - 1))\ndata$left &lt;- data$right - data$number_of_obs\n\n# Plot\nggplot(data, aes(ymin = 0)) +\n  geom_rect(aes(xmin = left, xmax = right, ymax = value, colour = group, fill = group)) +\n  xlab(\"Observations\") +\n  ylab(\"Value\") +\n  theme_minimal() +  # Use the default ggplot2 theme\n  theme(legend.position = \"none\")\n\n\n\n\nChart 2\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\ndata &lt;- data.frame(\n  Category = c(\"A\", \"B\", \"C\", \"D\"),\n  Value = c(10, 15, 8, 20)\n)\n\nbar_chart &lt;- ggplot(data, aes(x = Category, y = Value)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Bar Chart\")\n\nscatter_plot &lt;- ggplot(data, aes(x = Category, y = Value)) +\n  geom_point() +\n  labs(title = \"Scatter Plot\")\n\ncharts_combined &lt;- bar_chart + scatter_plot + plot_layout(ncol = 2)\n\nprint(charts_combined)\n\n\n\n\nChart 3\n\n# Load the ggplot2 and gridExtra libraries\nlibrary(ggplot2)\nlibrary(gridExtra)\n\n# Create a sample dataset\ndata &lt;- data.frame(\n  Category = c(\"Category A\", \"Category B\", \"Category C\", \"Category D\", \"Category E\", \"Category F\"),\n  Value1 = c(30, 50, 20, 40, 60, 25),\n  Value2 = c(40, 60, 30, 50, 70, 35)\n)\n\n# Create the first vertical bar chart (Value1)\nplot1 &lt;- ggplot(data, aes(x = Category, y = Value1, fill = Category)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = rainbow(nrow(data))) +\n  labs(title = \"Vertical Bar Chart 1\",\n       x = NULL,\n       y = \"Value 1\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  coord_flip()\n\n# Create the second vertical bar chart (Value2)\nplot2 &lt;- ggplot(data, aes(x = Category, y = Value2, fill = Category)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = rainbow(nrow(data))) +\n  labs(title = \"Vertical Bar Chart 2\",\n       x = NULL,\n       y = \"Value 2\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  coord_flip()\n\n# Arrange the two plots side by side\ngrid.arrange(plot1, plot2, ncol = 2)\n\n\n\n\nChart 4\n\n# Load the ggplot2 library\nlibrary(ggplot2)\n\n# Create a sample dataset\ndata &lt;- data.frame(\n  Category = c(\"Category A\", \"Category B\", \"Category C\"),\n  Value1 = c(30, 50, 20),\n  Value2 = c(40, 60, 30)\n)\n\n# Reshape the data to long format for overlapping columns\nlibrary(tidyr)\ndata_long &lt;- pivot_longer(data, cols = starts_with(\"Value\"), names_to = \"Variable\", values_to = \"Value\")\n\n# Create the column chart with slightly overlapping columns\nggplot(data_long, aes(x = Category, y = Value, fill = Variable)) +\n  geom_col(position = position_dodge(width = 0.7)) +  # Adjust the width for overlapping\n  labs(title = \"Overlapping Column Chart\",\n       x = \"Category\",\n       y = \"Value\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/Final Project/index.html",
    "href": "posts/Final Project/index.html",
    "title": "Final Presentation",
    "section": "",
    "text": "Presentation"
  },
  {
    "objectID": "posts/Assignment5/index.html",
    "href": "posts/Assignment5/index.html",
    "title": "Assignment 6",
    "section": "",
    "text": "Shiny app demo\n\n\nObjective: The goal of the Shiny app is to perform sentiment analysis on user-entered text using a custom AFINN dataset. It provides interactive visualizations, specifically bar and pie charts, to represent the sentiment scores and distribution of the entered text.\nComponents:\n\nDashboard Layout:\n\nThe dashboard consists of a header with the title “Sentiment Analysis App.”\nThe sidebar menu includes a “Charts” option.\n\nCharts Tab:\n\nThe “Charts” tab includes the following components:\n\nA header “Sentiment Analysis Charts.”\nA text input field labeled “Enter Text” for users to input the text they want to analyze.\nA bar chart displaying the sentiment score based on the AFINN data. The chart title is “Sentiment Score Bar Chart,” and the y-axis is labeled “Sentiment Score.”\nA pie chart illustrating the sentiment distribution of the entered text. The chart title is “Sentiment Score Pie Chart.”\n\n\n\nFunctionality:\n\nUsers can input text in the provided text input field.\nThe app calculates the sentiment score based on the AFINN data for the entered text.\nThe sentiment score is visually represented in both a bar chart and a pie chart.\nThe bar chart shows the overall sentiment score, and the pie chart depicts the distribution of positive and negative sentiments.\n\nUsage:\n\nUsers can enter any text in the input field to see the corresponding sentiment analysis charts.\nThe charts dynamically update based on the entered text, providing an interactive and real-time sentiment analysis experience.\n\nNote:\n\nThe app utilizes the AFINN data, which is a pre-defined list of words with associated sentiment scores.\nThe code assumes the existence of an AFINN data file named “afinn_data.csv.”"
  },
  {
    "objectID": "posts/Assignment5/index.html#ggplot-charts",
    "href": "posts/Assignment5/index.html#ggplot-charts",
    "title": "Assignment 5",
    "section": "GGPlot Charts",
    "text": "GGPlot Charts\n\nHistogram\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Generate a random dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram using ggplot2\nggplot(data.frame(x = data), aes(x)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 30) +\n  ggtitle(\"Histogram Example\") +\n  xlab(\"Values\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\nBar chart\n\n\nVertical\n\n# Generate a sample dataset (replace this with your own data)\ncategories &lt;- c(\"Category A\", \"Category B\", \"Category C\", \"Category D\")\nvalues &lt;- c(25, 40, 30, 20)\ndata &lt;- data.frame(categories, values)\n\n# Create a vertical bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  ggtitle(\"Vertical Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nHorizontal\n\n# Create a horizontal bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_col() +\n  ggtitle(\"Horizontal Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\") +\n  coord_flip()  # Flipping coordinates for a horizontal chart\n\n\n\n\n\n\nPie Chart\n\n# Create a pie chart using ggplot2\nggplot(data, aes(x = \"\", y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  ggtitle(\"Pie Chart\") +\n  coord_polar(\"y\")\n\n\n\n\n\n\nBox plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  group = rep(c(\"Group 1\", \"Group 2\", \"Group 3\"), each = 100),\n  values = c(rnorm(100, mean = 0, sd = 1), rnorm(100, mean = 2, sd = 1), rnorm(100, mean = 1, sd = 1))\n)\n\n# Create a boxplot using ggplot2\nggplot(data, aes(x = group, y = values, fill = group)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot Example\") +\n  xlab(\"Groups\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nScatter plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = 2 * rnorm(100) + rnorm(100)\n)\n\n# Create a scatterplot using ggplot2\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"darkorange\") +\n  ggtitle(\"Scatterplot Example\") +\n  xlab(\"X-axis\") +\n  ylab(\"Y-axis\")"
  },
  {
    "objectID": "posts/Assignment7/index.html",
    "href": "posts/Assignment7/index.html",
    "title": "Assignment 7",
    "section": "",
    "text": "Data set used found at “https://www2.imm.dtu.dk/pubdb/pubs/6010-full.html”\n\n\nGenerate a scatter plot\n\n# Read the CSV file\ndata &lt;- read.csv(\"AFINN-111.csv\")\n\n# Assuming the CSV file has columns named \"Word\" and \"Sentiment\"\n# Replace them with the actual column names in your CSV file\nword &lt;- data$Word\nsentiment &lt;- data$Sentiment\n\n# Generate a scatterplot\nplot(sentiment, main = \"Sentiment Scatterplot\", xlab = \"Word Index\", ylab = \"Sentiment\", col = \"blue\", pch = 16)\n\n\n\n\nIn this analysis, a CSV file containing sentiment data is processed in R to generate a scatterplot depicting the sentiment scores associated with different words. The file consists of two columns: “Word,” representing individual words, and “Sentiment,” indicating their corresponding sentiment scores as integers. The R script utilizes the base plot() function to create a scatterplot, with the x-axis representing the index of each word and the y-axis representing the associated sentiment score. Any missing or non-finite values are handled to ensure the accuracy of the plot. The resulting visualization provides an overview of the sentiment distribution across the words in the dataset, enabling a quick assessment of the sentiment patterns present in the data.\n\n\nGenerate a comparative scatter plot and bubble chart\n\n# Install and load the ggplot2 package\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Read the CSV file\ndata &lt;- read.csv(\"AFINN-111.csv\")\n\n# Create a new column for index\ndata$Index &lt;- seq_along(data$Word)\n\n# Assuming the CSV file has columns named \"Index\", \"Word\", and \"Sentiment\"\n# Replace them with the actual column names in your CSV file\nindex &lt;- data$Index\nword &lt;- data$Word\nsentiment &lt;- data$Sentiment\n\n# Remove rows with missing values\ndata &lt;- na.omit(data)\n\n# Create a comparative scatter plot with index ranges on the x-axis\nggplot(data, aes(x = Index, y = Sentiment)) +\n  geom_point(aes(size = abs(Sentiment)), color = \"blue\", alpha = 0.7) +\n  scale_size_continuous(range = c(3, 10)) +\n  labs(title = \"Comparative Scatter Plot\", x = \"Index Range\", y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n# Create a bubble chart with index ranges on the x-axis\nggplot(data, aes(x = Index, y = Sentiment, size = abs(Sentiment), color = Sentiment)) +\n  geom_point(alpha = 0.7) +\n  scale_size_continuous(range = c(3, 20)) +\n  labs(title = \"Bubble Chart\", x = \"Index Range\", y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\nThe provided R code utilizes the ggplot2 package to generate two distinct visualizations based on sentiment data extracted from a CSV file. The code begins by loading the necessary libraries and reading the data into a dataframe. A new index column is created to represent the row indices. Missing values are handled using the na.omit() function. The first visualization is a comparative scatter plot, where the x-axis displays index ranges, the y-axis represents sentiment scores, and point sizes correspond to the absolute values of sentiment scores. The second visualization is a bubble chart that maintains the same x and y-axis representations but introduces varying bubble sizes based on sentiment magnitude and color-coded sentiment scores. Both visualizations offer insights into the distribution and magnitude of sentiment scores across the dataset, providing a comprehensive exploration of sentiment trends with respect to index.\n\n\nGenerate a circular area chart\n\n# Install and load the ggplot2 package\ninstall.packages(\"ggplot2\")\n\nWarning: package 'ggplot2' is in use and will not be installed\n\nlibrary(ggplot2)\n\n# Read the CSV file\ndata &lt;- read.csv(\"AFINN-111.csv\")\n\n# Assuming the CSV file has columns named \"Word\" and \"Sentiment\"\n# Replace them with the actual column names in your CSV file\nword &lt;- data$Word\nsentiment &lt;- data$Sentiment\n\n# Create a data frame for plotting\nplot_data &lt;- data.frame(Word = word, Sentiment = sentiment)\n\n# Convert sentiment scores to positive values for line chart\nplot_data$Sentiment &lt;- abs(plot_data$Sentiment)\n\n# Remove missing values\nplot_data &lt;- na.omit(plot_data)\n\n# Sort the data by sentiment values\nplot_data &lt;- plot_data[order(plot_data$Sentiment, decreasing = TRUE), ]\n\n# Create an index column for x-axis\nplot_data$Index &lt;- seq_along(plot_data$Word)\n\n# Create a line chart with index on the x-axis\nggplot(plot_data, aes(x = Index, y = Sentiment, group = 1)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Sentiment Across Data\", x = \"Index\", y = \"Sentiment\") +\n  theme_minimal()\n\n\n\n\nThe line chart depicts the sentiment values across the dataset, where each point on the x-axis corresponds to the index of a word in the dataset. The sentiment values, represented on the y-axis, are derived from the “Sentiment” column, with absolute values used for visualization clarity. The blue line traces the fluctuation in sentiment, illustrating how sentiments vary across different entries in the dataset. The ascending peaks and descending troughs indicate the intensity and direction of sentiment changes, offering a visual narrative of sentiment trends throughout the dataset. The index on the x-axis provides a sequential ordering of words, allowing for a straightforward interpretation of sentiment patterns across the dataset."
  },
  {
    "objectID": "posts/Assignment6/index.html",
    "href": "posts/Assignment6/index.html",
    "title": "Assignment 5",
    "section": "",
    "text": "# Generate a random dataset\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram\nhist(data, col = \"skyblue\", main = \"Histogram Example\", xlab = \"Values\", ylab = \"Frequency\")"
  },
  {
    "objectID": "posts/Assignment6/index.html#ggplot-charts",
    "href": "posts/Assignment6/index.html#ggplot-charts",
    "title": "Assignment 5",
    "section": "GGPlot Charts",
    "text": "GGPlot Charts\n\nHistogram\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Generate a random dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram using ggplot2\nggplot(data.frame(x = data), aes(x)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 30) +\n  ggtitle(\"Histogram Example\") +\n  xlab(\"Values\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\nBar chart\n\n\nVertical\n\n# Generate a sample dataset (replace this with your own data)\ncategories &lt;- c(\"Category A\", \"Category B\", \"Category C\", \"Category D\")\nvalues &lt;- c(25, 40, 30, 20)\ndata &lt;- data.frame(categories, values)\n\n# Create a vertical bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  ggtitle(\"Vertical Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nHorizontal\n\n# Create a horizontal bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_col() +\n  ggtitle(\"Horizontal Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\") +\n  coord_flip()  # Flipping coordinates for a horizontal chart\n\n\n\n\n\n\nPie Chart\n\n# Create a pie chart using ggplot2\nggplot(data, aes(x = \"\", y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  ggtitle(\"Pie Chart\") +\n  coord_polar(\"y\")\n\n\n\n\n\n\nBox plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  group = rep(c(\"Group 1\", \"Group 2\", \"Group 3\"), each = 100),\n  values = c(rnorm(100, mean = 0, sd = 1), rnorm(100, mean = 2, sd = 1), rnorm(100, mean = 1, sd = 1))\n)\n\n# Create a boxplot using ggplot2\nggplot(data, aes(x = group, y = values, fill = group)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot Example\") +\n  xlab(\"Groups\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nScatter plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = 2 * rnorm(100) + rnorm(100)\n)\n\n# Create a scatterplot using ggplot2\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"darkorange\") +\n  ggtitle(\"Scatterplot Example\") +\n  xlab(\"X-axis\") +\n  ylab(\"Y-axis\")"
  },
  {
    "objectID": "posts/Assignment8/index.html",
    "href": "posts/Assignment8/index.html",
    "title": "Assignment 8",
    "section": "",
    "text": "Creating a Shiny dashboard using YouTube API data and hosting it on Quatro has been an intriguing yet challenging endeavor. Let me share a detailed account of the difficulties I encountered throughout this process:\n\n\nManaging the quotas and limits imposed by the YouTube API was a critical aspect. Exceeding these limitations could result in temporary restrictions or additional costs. Staying mindful of these constraints, especially when dealing with a substantial amount of data, was not feasible.\n\n\n\nSetting up proper authentication and authorization was complex. I had to deal with OAuth 2.0, API keys, and OAuth tokens, which I could not resolve as per the dashboard creation process.\n\n\n\nRetrieving and parsing the extensive JSON responses from the YouTube API demanded a solid understanding of the API’s structure. Effectively extracting relevant information for my Shiny dashboard required advanced data manipulation techniques, which did not prove possible finally.\n\n\n\nAs with any integration of external APIs, debugging issues and handling errors gracefully were constant challenges. Diagnosing problems related to data retrieval, authentication, or other API-related issues required a systematic approach, which could be inspected in greater depth with more time.\n\n\n\nDue to these challenges, creation of an insightful Shiny dashboard did not prove feasible. Leveraging YouTube API data provided a valuable user experience, and the development process taught me to approach challenges methodically, stay informed about changes, and seek community support when needed and we can possibly hope to resolve these as a future extension to this project."
  },
  {
    "objectID": "posts/Assignment8/index.html#ggplot-charts",
    "href": "posts/Assignment8/index.html#ggplot-charts",
    "title": "Assignment 8",
    "section": "GGPlot Charts",
    "text": "GGPlot Charts\n\nHistogram\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Generate a random dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram using ggplot2\nggplot(data.frame(x = data), aes(x)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 30) +\n  ggtitle(\"Histogram Example\") +\n  xlab(\"Values\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\nBar chart\n\n\nVertical\n\n# Generate a sample dataset (replace this with your own data)\ncategories &lt;- c(\"Category A\", \"Category B\", \"Category C\", \"Category D\")\nvalues &lt;- c(25, 40, 30, 20)\ndata &lt;- data.frame(categories, values)\n\n# Create a vertical bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  ggtitle(\"Vertical Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nHorizontal\n\n# Create a horizontal bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_col() +\n  ggtitle(\"Horizontal Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\") +\n  coord_flip()  # Flipping coordinates for a horizontal chart\n\n\n\n\n\n\nPie Chart\n\n# Create a pie chart using ggplot2\nggplot(data, aes(x = \"\", y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  ggtitle(\"Pie Chart\") +\n  coord_polar(\"y\")\n\n\n\n\n\n\nBox plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  group = rep(c(\"Group 1\", \"Group 2\", \"Group 3\"), each = 100),\n  values = c(rnorm(100, mean = 0, sd = 1), rnorm(100, mean = 2, sd = 1), rnorm(100, mean = 1, sd = 1))\n)\n\n# Create a boxplot using ggplot2\nggplot(data, aes(x = group, y = values, fill = group)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot Example\") +\n  xlab(\"Groups\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nScatter plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = 2 * rnorm(100) + rnorm(100)\n)\n\n# Create a scatterplot using ggplot2\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"darkorange\") +\n  ggtitle(\"Scatterplot Example\") +\n  xlab(\"X-axis\") +\n  ylab(\"Y-axis\")"
  },
  {
    "objectID": "posts/Assignment8/dashboard.html",
    "href": "posts/Assignment8/dashboard.html",
    "title": "Assignment 5",
    "section": "",
    "text": "# Generate a random dataset\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram\nhist(data, col = \"skyblue\", main = \"Histogram Example\", xlab = \"Values\", ylab = \"Frequency\")"
  },
  {
    "objectID": "posts/Assignment8/dashboard.html#ggplot-charts",
    "href": "posts/Assignment8/dashboard.html#ggplot-charts",
    "title": "Assignment 5",
    "section": "GGPlot Charts",
    "text": "GGPlot Charts\n\nHistogram\n\n# Load the ggplot2 package\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n# Generate a random dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- rnorm(1000)\n\n# Create a histogram using ggplot2\nggplot(data.frame(x = data), aes(x)) +\n  geom_histogram(fill = \"skyblue\", color = \"black\", bins = 30) +\n  ggtitle(\"Histogram Example\") +\n  xlab(\"Values\") +\n  ylab(\"Frequency\")\n\n\n\n\n\n\nBar chart\n\n\nVertical\n\n# Generate a sample dataset (replace this with your own data)\ncategories &lt;- c(\"Category A\", \"Category B\", \"Category C\", \"Category D\")\nvalues &lt;- c(25, 40, 30, 20)\ndata &lt;- data.frame(categories, values)\n\n# Create a vertical bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", color = \"black\") +\n  ggtitle(\"Vertical Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nHorizontal\n\n# Create a horizontal bar chart using ggplot2\nggplot(data, aes(x = categories, y = values, fill = categories)) +\n  geom_col() +\n  ggtitle(\"Horizontal Bar Chart\") +\n  xlab(\"Categories\") +\n  ylab(\"Values\") +\n  coord_flip()  # Flipping coordinates for a horizontal chart\n\n\n\n\n\n\nPie Chart\n\n# Create a pie chart using ggplot2\nggplot(data, aes(x = \"\", y = values, fill = categories)) +\n  geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n  ggtitle(\"Pie Chart\") +\n  coord_polar(\"y\")\n\n\n\n\n\n\nBox plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  group = rep(c(\"Group 1\", \"Group 2\", \"Group 3\"), each = 100),\n  values = c(rnorm(100, mean = 0, sd = 1), rnorm(100, mean = 2, sd = 1), rnorm(100, mean = 1, sd = 1))\n)\n\n# Create a boxplot using ggplot2\nggplot(data, aes(x = group, y = values, fill = group)) +\n  geom_boxplot() +\n  ggtitle(\"Boxplot Example\") +\n  xlab(\"Groups\") +\n  ylab(\"Values\")\n\n\n\n\n\n\nScatter plot\n\n# Generate a sample dataset (replace this with your own data)\nset.seed(123)\ndata &lt;- data.frame(\n  x = rnorm(100),\n  y = 2 * rnorm(100) + rnorm(100)\n)\n\n# Create a scatterplot using ggplot2\nggplot(data, aes(x = x, y = y)) +\n  geom_point(color = \"darkorange\") +\n  ggtitle(\"Scatterplot Example\") +\n  xlab(\"X-axis\") +\n  ylab(\"Y-axis\")"
  },
  {
    "objectID": "posts/Assignment8/index.html#plan-for-quarto-dashboard-for-project",
    "href": "posts/Assignment8/index.html#plan-for-quarto-dashboard-for-project",
    "title": "Assignment 8",
    "section": "",
    "text": "Creating a Shiny dashboard using YouTube API data and hosting it on Quatro has been an intriguing yet challenging endeavor. Let me share a detailed account of the difficulties I encountered throughout this process:\n\n\nManaging the quotas and limits imposed by the YouTube API was a critical aspect. Exceeding these limitations could result in temporary restrictions or additional costs. Staying mindful of these constraints, especially when dealing with a substantial amount of data, was not feasible.\n\n\n\nSetting up proper authentication and authorization was complex. I had to deal with OAuth 2.0, API keys, and OAuth tokens, which I could not resolve as per the dashboard creation process.\n\n\n\nRetrieving and parsing the extensive JSON responses from the YouTube API demanded a solid understanding of the API’s structure. Effectively extracting relevant information for my Shiny dashboard required advanced data manipulation techniques, which did not prove possible finally.\n\n\n\nAs with any integration of external APIs, debugging issues and handling errors gracefully were constant challenges. Diagnosing problems related to data retrieval, authentication, or other API-related issues required a systematic approach, which could be inspected in greater depth with more time.\n\n\n\nDue to these challenges, creation of an insightful Shiny dashboard did not prove feasible. Leveraging YouTube API data provided a valuable user experience, and the development process taught me to approach challenges methodically, stay informed about changes, and seek community support when needed and we can possibly hope to resolve these as a future extension to this project."
  },
  {
    "objectID": "posts/Assignment9/index.html",
    "href": "posts/Assignment9/index.html",
    "title": "Assignment 9",
    "section": "",
    "text": "# Set a CRAN mirror (choose a mirror that is geographically close to you)\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n# Install and load the required packages\ninstall.packages(c(\"quantmod\", \"tidyverse\", \"dygraphs\"))\n\nInstalling packages into 'C:/Users/heman/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'quantmod' successfully unpacked and MD5 sums checked\npackage 'tidyverse' successfully unpacked and MD5 sums checked\npackage 'dygraphs' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\heman\\AppData\\Local\\Temp\\RtmpS0sqdS\\downloaded_packages\n\nlapply(c(\"quantmod\", \"tidyverse\", \"dygraphs\"), require, character.only = TRUE)\n\nLoading required package: quantmod\n\n\nWarning: package 'quantmod' was built under R version 4.3.2\n\n\nLoading required package: xts\n\n\nWarning: package 'xts' was built under R version 4.3.2\n\n\nLoading required package: zoo\n\n\nWarning: package 'zoo' was built under R version 4.3.2\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\nLoading required package: TTR\n\n\nWarning: package 'TTR' was built under R version 4.3.2\n\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nLoading required package: tidyverse\n\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::first()  masks xts::first()\n✖ dplyr::lag()    masks stats::lag()\n✖ dplyr::last()   masks xts::last()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: dygraphs\n\n\nWarning: package 'dygraphs' was built under R version 4.3.2\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE"
  },
  {
    "objectID": "posts/Assignment9/index.html#fetch-google-data-using-quantmod-package",
    "href": "posts/Assignment9/index.html#fetch-google-data-using-quantmod-package",
    "title": "Assignment 9",
    "section": "Fetch google data using quantmod package",
    "text": "Fetch google data using quantmod package\n\n# Install and load the quantmod package\ninstall.packages(\"quantmod\")\n\nWarning: package 'quantmod' is in use and will not be installed\n\nlibrary(quantmod)\n\n# Specify the stock symbol and data source\nstock_symbol &lt;- \"GOOGL\"\ndata_source &lt;- \"yahoo\"\n\n# Fetch stock data for the past year\ngetSymbols(stock_symbol, src = data_source, from = Sys.Date() - 365, to = Sys.Date())\n\n[1] \"GOOGL\"\n\n# View the first few rows of the data\nhead(GOOGL)\n\n           GOOGL.Open GOOGL.High GOOGL.Low GOOGL.Close GOOGL.Volume\n2022-12-08      95.38      95.58     93.45       93.71     32213300\n2022-12-09      93.77      94.26     92.75       92.83     28225400\n2022-12-12      92.71      93.56     91.61       93.31     29420000\n2022-12-13      97.76      99.53     95.03       95.63     40593700\n2022-12-14      95.20      96.87     93.60       95.07     28733600\n2022-12-15      93.13      93.64     90.01       90.86     40107000\n           GOOGL.Adjusted\n2022-12-08          93.71\n2022-12-09          92.83\n2022-12-12          93.31\n2022-12-13          95.63\n2022-12-14          95.07\n2022-12-15          90.86\n\n# Plot the time series (adjusted closing prices)\nchartSeries(GOOGL$GOOGL.Adjusted, name = \"GOOGL Stock Prices\", type = \"line\")"
  },
  {
    "objectID": "posts/Assignment9/index.html#the-above-graph-describes-along-with-procedure-time-series-object-class",
    "href": "posts/Assignment9/index.html#the-above-graph-describes-along-with-procedure-time-series-object-class",
    "title": "Assignment 9",
    "section": "The above graph describes along with procedure: Time Series Object Class:",
    "text": "The above graph describes along with procedure: Time Series Object Class:\nThe time series data for Alphabet Inc. (GOOGL) obtained using quantmod is stored as an object of class xts (eXtensible Time Series). The xts class in R is designed to handle time series data efficiently, providing a convenient structure for analysis and visualization.\n\n2. Variables in the Time Series Object:\nThe time series object contains multiple variables or columns, each representing a specific aspect of the stock data. Here are some key variables:\n\nGOOGL.Open: Opening prices of GOOGL stock.\nGOOGL.High: Highest prices during the trading day.\nGOOGL.Low: Lowest prices during the trading day.\nGOOGL.Close: Closing prices of GOOGL stock.\nGOOGL.Volume: Volume of shares traded.\nGOOGL.Adjusted: Adjusted closing prices, accounting for corporate actions like dividends and stock splits.\n\n\n\n3. Data Exploration:\nThe head function is used to view the first few rows of the time series data. This provides a glimpse into the structure and content of the dataset, allowing us to understand the available variables and their values.\n\n\n4. Plotting the Time Series:\nThe chartSeries function is employed to create a line chart of the adjusted closing prices of GOOGL stock. This visualization helps in understanding the trend and fluctuations in stock prices over the specified time period.\n\n# Plotting time series data using TSstudio\n# install.packages(c(\"quantmod\", \"tidyverse\",\"TSstudio\"))\n# lapply(c(\"quantmod\", \"tidyverse\",\"TSstudio\"), require, character.only = TRUE)\n\nlibrary(TSstudio)\n\nWarning: package 'TSstudio' was built under R version 4.3.2\n\nquantmod::getSymbols(\"AAPL\", src=\"yahoo\")\n\n[1] \"AAPL\"\n\nclass(AAPL)\n\n[1] \"xts\" \"zoo\"\n\nts_plot(AAPL$AAPL.Adjusted, \n        title = \"Apple Stock prices\",\n        Ytitle = \"\")\n\n\n\n\nclass(AAPL) # What class is this object?\n\n[1] \"xts\" \"zoo\"\n\n# Some sample dataset from TSstudio\nts_seasonal(USgas, type = \"\") # month-year matrix data\n\nWarning in ts_seasonal(USgas, type = \"\"): The 'type' parameter is\ninvalide,using the default option - 'normal'\n\n\n\n\n\n# What class is USgas?\n\n# Sample charts\nts_heatmap(USgas)\n\n\n\n\nts_cor(USgas) # ACF and PACF\n\n\n\n\nts_lags(USgas, margin = .01)\n\n\n\n\nusgas=data.frame(USgas)\n\n\n# Plotting time series data using dygraph\n# install.packages(c(\"quantmod\", \"tidyverse\",\"dygraphs\"))\n# lapply(c(\"quantmod\", \"tidyverse\",\"dygraphs\"), require, character.only = TRUE)\n\nlibrary(dygraphs)\npar(family=\"Palatino\")\nquantmod::getSymbols(\"GOOGL\", src=\"yahoo\")\n\n[1] \"GOOGL\"\n\nclass(GOOGL)\n\n[1] \"xts\" \"zoo\"\n\nm = tail(GOOGL, n=30)\nm =m[,1:(ncol(m)-2)] # drop last two columns \nnames(m)&lt;-c('Open', 'High', 'Low', 'Close') # rename columns for plotting\npath &lt;- getwd()\nsetwd(\"C:/EPPS 6356/myBlog/posts/Assignment9\") # place dygraph.css into the same directory\ndygraph(m, main = \"Google Stock Prices (Candlestick Chart)\")  |&gt;  \n  dyCandlestickGroup(c('Open', 'High', 'Low', 'Close')) |&gt; \n  dyCandlestick()  |&gt; \n  dyLegend(show = \"always\", hideOnMouseOut = T) |&gt; \n  dyCSS(\"dygraph.css\")\n\n\n\n\n\n\n# Install and load required packages\ninstall.packages(c(\"quantmod\", \"forecast\", \"tseries\"))\n\nWarning: package 'quantmod' is in use and will not be installed\n\n\nInstalling packages into 'C:/Users/heman/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'forecast' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'forecast'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\forecast\\libs\\x64\\forecast.dll\nto\nC:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\forecast\\libs\\x64\\forecast.dll:\nPermission denied\n\n\nWarning: restored 'forecast'\n\n\npackage 'tseries' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'tseries'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\tseries\\libs\\x64\\tseries.dll\nto C:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\tseries\\libs\\x64\\tseries.dll:\nPermission denied\n\n\nWarning: restored 'tseries'\n\n\n\nThe downloaded binary packages are in\n    C:\\Users\\heman\\AppData\\Local\\Temp\\RtmpS0sqdS\\downloaded_packages\n\nlapply(c(\"quantmod\", \"forecast\", \"tseries\"), require, character.only = TRUE)\n\nLoading required package: forecast\n\n\nWarning: package 'forecast' was built under R version 4.3.2\n\n\nLoading required package: tseries\n\n\nWarning: package 'tseries' was built under R version 4.3.2\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\n# Fetch stock data for Google and Apple using quantmod\ngetSymbols(\"GOOGL\", src = \"yahoo\")\n\n[1] \"GOOGL\"\n\ngetSymbols(\"AAPL\", src = \"yahoo\")\n\n[1] \"AAPL\"\n\n# Extract adjusted closing prices\ngoogl_prices &lt;- Cl(GOOGL)\naapl_prices &lt;- Cl(AAPL)\n\n# Combine data into a data frame\nstock_data &lt;- data.frame(GOOGL = googl_prices, AAPL = aapl_prices)\n\n# Plot the time series data\npar(mfrow = c(2, 1), mar = c(4, 4, 2, 1), oma = c(0, 0, 2, 0))\nplot(googl_prices, main = \"Google Stock Prices\", ylab = \"Adjusted Close\", col = \"blue\", type = \"l\")\nplot(aapl_prices, main = \"Apple Stock Prices\", ylab = \"Adjusted Close\", col = \"red\", type = \"l\")\n\n\n\n# Trend Analysis\n# You can visually inspect the plot for trends. Additionally, you can use trend analysis methods.\n\n# Stationarity Analysis\n# Use the Augmented Dickey-Fuller test to check for stationarity\nadf_test_googl &lt;- adf.test(googl_prices)\nadf_test_aapl &lt;- adf.test(aapl_prices)\n\ncat(\"ADF Test for Google Stock Prices:\\n\", \"p-value =\", adf_test_googl$p.value, \"\\n\")\n\nADF Test for Google Stock Prices:\n p-value = 0.7163732 \n\ncat(\"ADF Test for Apple Stock Prices:\\n\", \"p-value =\", adf_test_aapl$p.value, \"\\n\")\n\nADF Test for Apple Stock Prices:\n p-value = 0.9591422 \n\n# pdq Analysis\n# Use auto.arima to identify potential parameters\nlibrary(forecast)\nauto_arima_googl &lt;- auto.arima(googl_prices)\nauto_arima_aapl &lt;- auto.arima(aapl_prices)\n\ncat(\"ARIMA Parameters for Google Stock Prices:\\n\", auto_arima_googl$arma, \"\\n\")\n\nARIMA Parameters for Google Stock Prices:\n 1 1 0 0 1 1 0 \n\ncat(\"ARIMA Parameters for Apple Stock Prices:\\n\", auto_arima_aapl$arma, \"\\n\")\n\nARIMA Parameters for Apple Stock Prices:\n 5 0 0 0 1 2 0 \n\n\nIn this time series analysis, we examine the historical stock prices of Google (GOOGL) and Apple (AAPL) to gain insights into three key aspects: trend, stationarity, and the potential parameters (pdq) for ARIMA models.\n\n\ni. Trend Analysis:\nVisual inspection of the time series plots reveals trends in both Google and Apple stock prices. In the plots, we observe fluctuations in the adjusted closing prices over time. The visual analysis provides a qualitative understanding of the general direction of the stock prices. However, a more quantitative trend analysis could involve using methods like moving averages or decomposition techniques to identify underlying patterns.\n\n\nii. Stationarity Analysis:\nTo assess stationarity, we employ the Augmented Dickey-Fuller (ADF) test, which checks for the presence of a unit root in the time series data. The null hypothesis of the ADF test is that the time series has a unit root and is non-stationary. A lower p-value provides stronger evidence against stationarity.\nResults from the ADF test indicate the following:\n\nGoogle (GOOGL):\n\nADF Test p-value: &lt;p-value&gt;\nInterpretation: &lt;Stationary or Non-Stationary&gt;\n\nApple (AAPL):\n\nADF Test p-value: &lt;p-value&gt;\nInterpretation: &lt;Stationary or Non-Stationary&gt;\n\n\nThe stationarity analysis informs us about the nature of the time series and whether further differencing or transformations might be needed for modeling.\n\n\niii. pdq Analysis:\nTo identify potential parameters (p, d, q) for ARIMA models, we utilize the auto.arima function from the forecast package. This function automatically searches for the best-fitting ARIMA model based on the Akaike Information Criterion (AIC). The identified parameters provide insights into the autoregressive, differencing, and moving average components of the time series.\nResults from the pdq analysis indicate the following:\n\nGoogle (GOOGL):\n\nARIMA Parameters: &lt;p, d, q&gt;\n\nApple (AAPL):\n\nARIMA Parameters: &lt;p, d, q&gt;\n\n\nThe pdq analysis guides us in selecting appropriate parameters for ARIMA modeling, facilitating the construction of predictive models based on historical stock prices.\nIn summary, this time series analysis provides a comprehensive understanding of trends, stationarity, and potential ARIMA parameters for both Google and Apple stock prices. Further refinements and model fitting can be conducted based on the specific requirements of forecasting or predictive analytics."
  },
  {
    "objectID": "posts/Assignment10/index.html",
    "href": "posts/Assignment10/index.html",
    "title": "Assignment 10",
    "section": "",
    "text": "options(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n\nLeaflet for Geo-Location\nThe R script utilizes the leaflet package to generate an interactive map showcasing my current location. The script employs latitude and longitude coordinates to pinpoint these locations on the map.The functionality includes the addition of default OpenStreetMap tiles, markers at specified geographical coordinates, and interactive pop-up labels for each location. Additionally, a scale control is incorporated for enhanced map navigation. The script offers flexibility for customization, making it an ideal starting point for users aiming to create and display personalized leaflet maps on their websites.\n\n\nMedian age spatial analysis\nIn this R script, we leverage the tidycensus and ggplot2 packages to analyze and visualize time series data pertaining to the median age of U.S. states from 2009 to 2019 using Census Bureau’s American Community Survey (ACS) data. The script retrieves and processes demographic information for the years 2009 and 2019, focusing specifically on the variable “B01002_001” representing median age. By employing the ggplot2 package, we create a choropleth map that vividly displays the median age for each state in the specified years. The color intensity on the map represents the median age, allowing for easy visual comparison and trend observation across the two years. This analysis provides valuable insights into the temporal evolution of the median age distribution at the state level, offering a compelling visualization of demographic changes over the decade.\n\n# Install and load the required packages\ninstall.packages(c(\"tidycensus\", \"tigris\", \"ggplot2\", \"censusapi\"))\n\nInstalling packages into 'C:/Users/heman/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'tidycensus' successfully unpacked and MD5 sums checked\npackage 'tigris' successfully unpacked and MD5 sums checked\npackage 'ggplot2' successfully unpacked and MD5 sums checked\npackage 'censusapi' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\heman\\AppData\\Local\\Temp\\Rtmpig6aIY\\downloaded_packages\n\nlibrary(tidycensus)\n\nWarning: package 'tidycensus' was built under R version 4.3.2\n\nlibrary(tigris)\n\nWarning: package 'tigris' was built under R version 4.3.2\n\n\nTo enable caching of data, set `options(tigris_use_cache = TRUE)`\nin your R script or .Rprofile.\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.3.2\n\nlibrary(censusapi)\n\nWarning: package 'censusapi' was built under R version 4.3.2\n\n\n\nAttaching package: 'censusapi'\n\n\nThe following object is masked from 'package:methods':\n\n    getFunction\n\n# Set your Census API key\n# census_api_key(\"0619fde53378e1a58ac22a188b6b12c64c2943cd\", install = TRUE)\n\n# Load ACS variables\nacs19 &lt;- tidycensus::load_variables(2019, \"acs5\", cache = TRUE)\nacs19_Profile &lt;- tidycensus::load_variables(2019, \"acs5/profile\", cache = TRUE)\n\n# Get median age data for 2019\nus_median_age19 &lt;- get_acs(\n  geography = \"state\",\n  variables = \"B01002_001\",\n  year = 2009,\n  survey = \"acs1\",\n  geometry = TRUE,\n  resolution = \"20m\"\n) %&gt;%\n  shift_geometry()\n\nGetting data from the 2009 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n  |                                                                            \n  |=                                                                     |   2%\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |===                                                                   |   4%\n  |                                                                            \n  |===                                                                   |   5%\n  |                                                                            \n  |====                                                                  |   6%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |======                                                                |   8%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  12%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  14%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |===========================                                           |  39%\n  |                                                                            \n  |============================                                          |  40%\n  |                                                                            \n  |=============================                                         |  42%\n  |                                                                            \n  |==============================                                        |  43%\n  |                                                                            \n  |===================================                                   |  49%\n  |                                                                            \n  |===============================================                       |  67%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================== |  98%\n  |                                                                            \n  |======================================================================|  99%\n  |                                                                            \n  |======================================================================| 100%\n\n# Plot the map with Arial font\nggplot(data = us_median_age19, aes(fill = estimate)) + \n  geom_sf(col = \"white\") +\n  theme_bw() +\n  scale_fill_distiller(\n    palette = \"PuBuGn\",\n    direction = 1\n  ) + \n  labs(\n    title = \"Median Age by State, 2009\",\n    caption = \"Data source: 2009 1-year ACS, US Census Bureau\",\n    fill = \"\"\n  ) +\n  theme(\n    legend.position = c(0.08, 0.6),\n    legend.direction = \"vertical\"\n  )\n\n\n\n\n\n# Install and load the required packages\ninstall.packages(c(\"tidycensus\", \"tigris\", \"ggplot2\", \"censusapi\"))\n\nWarning: packages 'tidycensus', 'tigris', 'ggplot2', 'censusapi' are in use and\nwill not be installed\n\nlibrary(tidycensus)\nlibrary(tigris)\nlibrary(ggplot2)\nlibrary(censusapi)\n\n# Set your Census API key\n# census_api_key(\"0619fde53378e1a58ac22a188b6b12c64c2943cd\", install = TRUE)\n\n# Load ACS variables\nacs19 &lt;- tidycensus::load_variables(2019, \"acs5\", cache = TRUE)\nacs19_Profile &lt;- tidycensus::load_variables(2019, \"acs5/profile\", cache = TRUE)\n\n# Get median age data for 2019\nus_median_age19 &lt;- get_acs(\n  geography = \"state\",\n  variables = \"B01002_001\",\n  year = 2019,\n  survey = \"acs1\",\n  geometry = TRUE,\n  resolution = \"20m\"\n) %&gt;%\n  shift_geometry()\n\nGetting data from the 2019 1-year ACS\n\n\nThe 1-year ACS provides data for geographies with populations of 65,000 and greater.\n\n\nDownloading feature geometry from the Census website.  To cache shapefiles for use in future sessions, set `options(tigris_use_cache = TRUE)`.\n\n\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |================================================                      |  68%\n  |                                                                            \n  |======================================================================| 100%\n\n# Plot the map with Arial font\nggplot(data = us_median_age19, aes(fill = estimate)) + \n  geom_sf(col = \"white\") +\n  theme_bw() +\n  scale_fill_distiller(\n    palette = \"PuBuGn\",\n    direction = 1\n  ) + \n  labs(\n    title = \"Median Age by State, 2019\",\n    caption = \"Data source: 2019 1-year ACS, US Census Bureau\",\n    fill = \"\"\n  ) +\n  theme(\n    legend.position = c(0.08, 0.6),\n    legend.direction = \"vertical\"\n  )\n\n\n\n\n\n\nIncome analysis across 5 years for texas\nThe provided R script utilizes Census data retrieved through the American Community Survey (ACS) API to analyze and visualize income information for Texas in the year 2009. The primary variables of interest are contained in the “B19013_001” category, representing median household income. The script first fetches tract-level income data for the entire state of Texas and generates a basic plot of the estimated incomes across different tracts. Subsequently, it employs the tmap package to create a thematic map for Dallas County, Texas, displaying the spatial distribution of median household incomes at the tract level in 2009. The mapview package is then utilized to provide an interactive map view of the income data for Dallas County, offering a dynamic exploration of the geographic patterns of income distribution within the specified region. This analysis contributes valuable insights into the economic landscape of Texas in 2009, focusing on median household income disparities at both state and county levels.\n\n# Install and load the required packages\ninstall.packages(c(\"tidyverse\", \"ggmap\", \"mapproj\", \"tidycensus\", \"tigris\", \"tmap\", \"mapview\"))\n\nWarning: packages 'tidycensus', 'tigris' are in use and will not be installed\n\n\nInstalling packages into 'C:/Users/heman/AppData/Local/R/win-library/4.3'\n(as 'lib' is unspecified)\n\n\npackage 'tidyverse' successfully unpacked and MD5 sums checked\npackage 'ggmap' successfully unpacked and MD5 sums checked\npackage 'mapproj' successfully unpacked and MD5 sums checked\n\n\nWarning: cannot remove prior installation of package 'mapproj'\n\n\nWarning in file.copy(savedcopy, lib, recursive = TRUE): problem copying\nC:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\00LOCK\\mapproj\\libs\\x64\\mapproj.dll\nto C:\\Users\\heman\\AppData\\Local\\R\\win-library\\4.3\\mapproj\\libs\\x64\\mapproj.dll:\nPermission denied\n\n\nWarning: restored 'mapproj'\n\n\npackage 'tmap' successfully unpacked and MD5 sums checked\npackage 'mapview' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\heman\\AppData\\Local\\Temp\\Rtmpig6aIY\\downloaded_packages\n\nlapply(c(\"tidyverse\", \"ggmap\", \"mapproj\", \"tidycensus\", \"tigris\", \"tmap\", \"mapview\"), require, character.only = TRUE)\n\nLoading required package: tidyverse\n\n\nWarning: package 'tidyverse' was built under R version 4.3.2\n\n\nWarning: package 'stringr' was built under R version 4.3.2\n\n\nWarning: package 'lubridate' was built under R version 4.3.2\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nLoading required package: ggmap\n\n\nWarning: package 'ggmap' was built under R version 4.3.2\n\n\nℹ Google's Terms of Service: &lt;https://mapsplatform.google.com&gt;\n  Stadia Maps' Terms of Service: &lt;https://stadiamaps.com/terms-of-service/&gt;\n  OpenStreetMap's Tile Usage Policy: &lt;https://operations.osmfoundation.org/policies/tiles/&gt;\nℹ Please cite ggmap if you use it! Use `citation(\"ggmap\")` for details.\nLoading required package: mapproj\n\n\nWarning: package 'mapproj' was built under R version 4.3.2\n\n\nLoading required package: maps\n\n\nWarning: package 'maps' was built under R version 4.3.2\n\n\n\nAttaching package: 'maps'\n\nThe following object is masked from 'package:purrr':\n\n    map\n\nLoading required package: tmap\n\n\nWarning: package 'tmap' was built under R version 4.3.2\n\n\nBreaking News: tmap 3.x is retiring. Please test v4, e.g. with\nremotes::install_github('r-tmap/tmap')\nLoading required package: mapview\n\n\nWarning: package 'mapview' was built under R version 4.3.2\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] TRUE\n\n[[5]]\n[1] TRUE\n\n[[6]]\n[1] TRUE\n\n[[7]]\n[1] TRUE\n\nlibrary(tidycensus)\noptions(tigris_use_cache = TRUE)\n\n# Collect Census data for Texas income in 2009\ntx_income &lt;- get_acs(\n  geography = \"tract\", \n  variables = \"B19013_001\",\n  state = \"TX\", \n  year = 2009,\n  geometry = TRUE\n)\n\nGetting data from the 2005-2009 5-year ACS\n\n# Plot the income data\nplot(tx_income[\"estimate\"])\n\n\n\n# Load the tmap package\nlibrary(tmap)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n# Collect Dallas County income data for 2009\ndallas_income &lt;- get_acs(\n  geography = \"tract\",\n  variables = \"B19013_001\",\n  year = 2009,\n  state = \"TX\",\n  county = \"Dallas\",\n  geometry = TRUE\n)\n\nGetting data from the 2005-2009 5-year ACS\n\n# Create a thematic map using tmap\ntm_shape(dallas_income) + \n  tm_fill(col = \"estimate\", palette = \"YlOrRd\", alpha = 0.5)\n\n\n\n\n\n# Load the mapview package\nlibrary(mapview)\n\n# Display the map using mapview\nmapView(dallas_income, zcol = \"estimate\")"
  }
]